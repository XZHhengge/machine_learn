{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['.ipynb_checkpoints', 'batches.meta', 'data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5', 'readme.html', 'test_batch']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "CIFAR_DIR = \".\\deep_learn\\cifar-10-batches-py\"\n",
    "print(os.listdir(CIFAR_DIR))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(50000, 3072)\n(50000,)\n",
      "(10000, 3072)\n(10000,)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"read data from data file.\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='bytes')\n",
    "        return data[b'data'], data[b'labels']\n",
    "\n",
    "# tensorflow.Dataset.\n",
    "class CifarData:\n",
    "    def __init__(self, filenames, need_shuffle):\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "        for filename in filenames:\n",
    "            data, labels = load_data(filename)\n",
    "            all_data.append(data)\n",
    "            all_labels.append(labels)\n",
    "        self._data = np.vstack(all_data)\n",
    "        self._data = self._data / 127.5 - 1\n",
    "        self._labels = np.hstack(all_labels)\n",
    "        print(self._data.shape)\n",
    "        print(self._labels.shape)\n",
    "        \n",
    "        self._num_examples = self._data.shape[0]\n",
    "        self._need_shuffle = need_shuffle\n",
    "        self._indicator = 0\n",
    "        if self._need_shuffle:\n",
    "            self._shuffle_data()\n",
    "            \n",
    "    def _shuffle_data(self):\n",
    "        # [0,1,2,3,4,5] -> [5,3,2,4,0,1]\n",
    "        p = np.random.permutation(self._num_examples)\n",
    "        self._data = self._data[p]\n",
    "        self._labels = self._labels[p]\n",
    "    \n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"return batch_size examples as a batch.\"\"\"\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self._num_examples:\n",
    "            if self._need_shuffle:\n",
    "                self._shuffle_data()\n",
    "                self._indicator = 0\n",
    "                end_indicator = batch_size\n",
    "            else:\n",
    "                raise Exception(\"have no more examples\")\n",
    "        if end_indicator > self._num_examples:\n",
    "            raise Exception(\"batch size is larger than all examples\")\n",
    "        batch_data = self._data[self._indicator: end_indicator]\n",
    "        batch_labels = self._labels[self._indicator: end_indicator]\n",
    "        self._indicator = end_indicator\n",
    "        return batch_data, batch_labels\n",
    "\n",
    "train_filenames = [os.path.join(CIFAR_DIR, 'data_batch_%d' % i) for i in range(1, 6)]\n",
    "test_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\n",
    "\n",
    "train_data = CifarData(train_filenames, True)\n",
    "test_data = CifarData(test_filenames, False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-0722d70bc054>:15: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-3-0722d70bc054>:28: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-3-0722d70bc054>:73: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-3-0722d70bc054>:74: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse keras.layers.dense instead.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 3072])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "# [None], eg: [0,5,6,3]\n",
    "x_image = tf.reshape(x, [-1, 3, 32, 32])\n",
    "# 32*32\n",
    "x_image = tf.transpose(x_image, perm=[0, 2, 3, 1])\n",
    "\n",
    "# conv1: 神经元图， feature_map, 输出图像\n",
    "conv1_1 = tf.layers.conv2d(x_image,\n",
    "                         32, # output channel number\n",
    "                         (3,3), # kernel size\n",
    "                         padding = 'same',\n",
    "                         activation = tf.nn.relu,\n",
    "                         name = 'conv1_1')\n",
    "\n",
    "conv1_2 = tf.layers.conv2d(conv1_1,\n",
    "                         32, # output channel number\n",
    "                         (3,3), # kernel size\n",
    "                         padding = 'same',\n",
    "                         activation = tf.nn.relu,\n",
    "                         name = 'conv1_2')\n",
    "\n",
    "# 16 * 16\n",
    "pooling1 = tf.layers.max_pooling2d(conv1_2,\n",
    "                                   (2, 2), # kernel size\n",
    "                                   (2, 2), # stride\n",
    "                                   name = 'pool1')\n",
    "\n",
    "\n",
    "conv2_1 = tf.layers.conv2d(pooling1,\n",
    "                         32, # output channel number\n",
    "                         (3,3), # kernel size\n",
    "                         padding = 'same',\n",
    "                         activation = tf.nn.relu,\n",
    "                         name = 'conv2_1')\n",
    "\n",
    "\n",
    "conv2_2 = tf.layers.conv2d(conv2_1,\n",
    "                         32, # output channel number\n",
    "                         (3,3), # kernel size\n",
    "                         padding = 'same',\n",
    "                         activation = tf.nn.relu,\n",
    "                         name = 'conv2_2')\n",
    "\n",
    "# 8 * 8\n",
    "pooling2 = tf.layers.max_pooling2d(conv2_2,\n",
    "                                   (2, 2), # kernel size\n",
    "                                   (2, 2), # stride\n",
    "                                   name = 'pool2')\n",
    "\n",
    "conv3_1 = tf.layers.conv2d(pooling2,\n",
    "                         32, # output channel number\n",
    "                         (3,3), # kernel size\n",
    "                         padding = 'same',\n",
    "                         activation = tf.nn.relu,\n",
    "                         name = 'conv3_1')\n",
    "\n",
    "\n",
    "conv3_2 = tf.layers.conv2d(conv3_1,\n",
    "                         32, # output channel number\n",
    "                         (3,3), # kernel size\n",
    "                         padding = 'same',\n",
    "                         activation = tf.nn.relu,\n",
    "                         name = 'conv3_2')\n",
    "\n",
    "# 4 * 4 * 32\n",
    "pooling3 = tf.layers.max_pooling2d(conv3_2,\n",
    "                                   (2, 2), # kernel size\n",
    "                                   (2, 2), # stride\n",
    "                                   name = 'pool3')\n",
    "# [None, 4 * 4 * 32]\n",
    "flatten = tf.layers.flatten(pooling3)\n",
    "y_ = tf.layers.dense(flatten, 10)\n",
    "\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
    "# y_ -> sofmax\n",
    "# y -> one_hot\n",
    "# loss = ylogy_\n",
    "\n",
    "# indices\n",
    "predict = tf.argmax(y_, 1)\n",
    "# [1,0,1,1,1,0,0,0]\n",
    "correct_prediction = tf.equal(predict, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\n",
    "\n",
    "with tf.name_scope('train_op'):\n",
    "    train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[-0.74117647 -0.74117647 -0.71764706 ... -0.38039216 -0.38823529\n -0.38039216] 1\n[-0.34117647 -0.31764706 -0.38039216 ...  0.7254902   0.82745098\n  0.88235294] 1\n",
      "[-0.3254902  -0.01176471  0.19215686 ... -0.22352941 -0.24705882\n -0.27843137] 1\n[-0.94509804 -0.96862745 -0.96862745 ...  0.71764706  0.70980392\n  0.56078431] 1\n[-0.15294118 -0.09803922  0.05098039 ... -0.45098039 -0.45098039\n -0.3254902 ] 2\n",
      "[-0.15294118 -0.16862745 -0.16078431 ... -0.64705882 -0.56862745\n -0.59215686] 8\n[ 0.45098039  0.40392157  0.41960784 ... -0.6        -0.59215686\n -0.56862745] 1\n[-0.54509804 -0.41960784 -0.00392157 ... -0.18431373 -0.19215686\n -0.25490196] 2\n",
      "[-0.16078431 -0.23137255 -0.27843137 ... -0.4745098  -0.00392157\n -0.06666667] 6\n[0.78823529 0.52156863 0.21568627 ... 0.34117647 0.33333333 0.44313725] 9\n[-0.65490196 -0.62352941 -0.58431373 ...  0.4745098   0.51372549\n  0.56862745] 1\n",
      "[ 0.12156863  0.11372549  0.10588235 ... -0.23137255 -0.2627451\n -0.24705882] 0\n[-0.67058824 -0.61568627 -0.6627451  ... -0.37254902 -0.40392157\n -0.42745098] 1\n[0.99215686 0.62352941 0.22352941 ... 1.         1.         1.        ] 0\n",
      "[-1. -1. -1. ... -1. -1. -1.] 5\n[ 0.52941176  0.61568627  0.65490196 ... -0.09019608 -0.27058824\n -0.45882353] 9\n[0.85098039 0.86666667 0.86666667 ... 0.48235294 0.30196078 0.41960784] 1\n",
      "[ 0.10588235  0.16078431  0.16078431 ...  0.05098039  0.08235294\n -0.11372549] 2\n[-0.15294118 -0.18431373 -0.2        ... -0.77254902 -0.6627451\n -0.41176471] 1\n[0.49019608 0.4745098  0.43529412 ... 0.6627451  0.63137255 0.7254902 ] 6\n",
      "[0.30196078 0.24705882 0.20784314 ... 0.03529412 0.56078431 0.38039216] 5\n[-0.75686275 -0.76470588 -0.81176471 ... -0.41176471 -0.40392157\n -0.43529412] 4\n[ 0.74901961  0.78039216  0.77254902 ... -0.89803922 -0.85098039\n -0.84313725] 4\n",
      "[-0.2627451  -0.45098039 -0.2        ... -0.55294118 -0.5372549\n -0.33333333] 2\n[-0.12156863  0.23137255  0.23137255 ... -0.28627451 -0.29411765\n -0.28627451] 4\n[-0.0745098  -0.4745098  -0.25490196 ...  0.24705882  0.23921569\n  0.20784314] 1\n",
      "[-0.17647059 -0.24705882 -0.1372549  ... -0.49019608 -0.54509804\n -0.50588235] 6\n[-0.2627451  -0.2627451  -0.29411765 ... -0.27058824 -0.29411765\n -0.3254902 ] 4\n[-0.36470588 -0.45098039 -0.46666667 ... -0.33333333 -0.2\n -0.12941176] 3\n",
      "[ 0.82745098  0.82745098  0.81960784 ... -0.12941176 -0.14509804\n -0.17647059] 1\n[0.51372549 0.51372549 0.52941176 ... 0.42745098 0.39607843 0.27843137] 7\n[-0.80392157 -0.85098039 -0.74901961 ... -0.95294118 -0.96078431\n -0.96078431] 2\n",
      "[ 0.99215686  0.97647059  0.98431373 ... -0.6627451  -0.63921569\n -0.68627451] 1\n[-0.41960784 -0.42745098 -0.44313725 ... -0.85098039 -0.85882353\n -0.85882353] 5\n[ 0.02745098  0.05882353  0.03529412 ... -0.09019608 -0.12941176\n -0.17647059] 8\n",
      "[-0.94509804 -0.95294118 -0.95294118 ... -0.73333333 -0.73333333\n -0.74117647] 9\n[-0.17647059 -0.2        -0.2        ...  0.1372549   0.08235294\n  0.11372549] 9\n[ 0.14509804  0.17647059  0.21568627 ... -0.18431373 -0.2\n -0.23137255] 4\n",
      "[ 0.10588235  0.08235294  0.0745098  ... -0.46666667 -0.49019608\n -0.4745098 ] 0\n[-0.28627451 -0.09803922 -0.01960784 ... -0.80392157  0.24705882\n  0.92156863] 5\n[-0.50588235 -0.49803922 -0.21568627 ... -0.37254902 -0.36470588\n -0.33333333] 4\n",
      "[-0.50588235 -0.49019608 -0.41960784 ... -0.17647059 -0.16862745\n -0.18431373] 4\n[-0.70980392 -0.70980392 -0.70196078 ... -0.09019608  0.01960784\n  0.08235294] 1\n[0.91372549 0.88235294 0.85098039 ... 0.64705882 0.63137255 0.6627451 ] 9\n",
      "[-0.42745098 -0.42745098 -0.42745098 ... -0.36470588 -0.31764706\n -0.25490196] 9\n[ 0.65490196  0.6627451   0.63137255 ... -0.9372549  -0.92156863\n -0.90588235] 3\n[0.45098039 0.42745098 0.42745098 ... 0.42745098 0.42745098 0.42745098] 2\n",
      "[-0.84313725 -0.67843137 -0.67843137 ... -0.10588235 -0.49803922\n -0.88235294] 7\n[-0.61568627 -0.67843137 -0.73333333 ... -0.12941176 -0.1372549\n -0.11372549] 7\n[-0.52941176 -0.67058824 -0.65490196 ...  0.2627451   0.2627451\n  0.27843137] 7\n",
      "[-0.20784314 -0.18431373 -0.19215686 ...  0.23137255  0.24705882\n  0.30980392] 6\n[-0.6627451  -0.54509804 -0.56078431 ...  0.19215686  0.17647059\n  0.09803922] 4\n[ 0.58431373  0.58431373  0.8745098  ... -0.81960784 -0.80392157\n -0.83529412] 9\n",
      "[0.97647059 0.9372549  0.98431373 ... 0.98431373 0.99215686 1.        ] 9\n[ 0.27058824  0.27058824  0.28627451 ...  0.09019608 -0.02745098\n -0.0745098 ] 8\n[-0.06666667  0.0745098   0.0745098  ... -0.11372549 -0.22352941\n -0.49019608] 4\n",
      "[-0.0745098   0.11372549  0.01176471 ... -0.27843137 -0.37254902\n -0.38823529] 4\n[-0.28627451 -0.29411765 -0.29411765 ... -0.86666667 -0.90588235\n -0.90588235] 8\n[-0.21568627 -0.27058824 -0.31764706 ... -0.59215686 -0.59215686\n -0.59215686] 3\n",
      "[ 0.58431373  0.60784314  0.63137255 ... -0.39607843 -0.16078431\n  0.12156863] 5\n[0.81176471 0.82745098 0.86666667 ... 0.12156863 0.09803922 0.15294118] 1\n[-0.67058824 -0.63921569 -0.61568627 ... -0.36470588 -0.52941176\n -0.68627451] 4\n",
      "[-0.23921569 -0.25490196 -0.36470588 ... -0.27843137 -0.20784314\n -0.27058824] 4\n[-0.38823529 -0.31764706 -0.20784314 ... -0.49019608 -0.59215686\n -0.42745098] 6\n[ 0.41176471  0.39607843  0.39607843 ... -0.78039216 -0.74117647\n -0.73333333] 8\n",
      "[ 0.56862745  0.60784314  0.61568627 ... -0.56078431 -0.49019608\n -0.49019608] 7\n[ 0.09803922  0.14509804  0.12156863 ... -0.38823529 -0.49803922\n -0.38823529] 4\n[-0.61568627 -0.62352941 -0.61568627 ...  0.20784314  0.18431373\n  0.2       ] 4\n",
      "[ 0.41960784  0.41176471  0.41960784 ... -0.67058824 -0.6627451\n -0.63137255] 9\n[0.34117647 0.44313725 0.60784314 ... 0.05098039 0.08235294 0.1372549 ] 0\n[-0.14509804 -0.37254902 -0.34117647 ...  0.01960784 -0.0745098\n -0.11372549] 8\n",
      "[0.49019608 0.34117647 0.24705882 ... 0.15294118 0.09803922 0.09019608] 2\n[ 0.27058824  0.24705882  0.2627451  ... -0.44313725 -0.42745098\n -0.43529412] 8\n[-0.39607843 -0.17647059  0.33333333 ... -0.50588235 -0.4745098\n -0.45882353] 7\n",
      "[-0.52941176 -0.54509804 -0.56078431 ... -0.34901961 -0.51372549\n -0.35686275] 2\n[0.8745098  0.86666667 0.89019608 ... 0.41960784 0.40392157 0.51372549] 9\n[-0.24705882 -0.23137255 -0.22352941 ... -0.40392157 -0.37254902\n -0.37254902] 9\n",
      "[-0.33333333 -0.43529412 -0.51372549 ...  0.54509804  0.63137255\n  0.39607843] 3\n[-0.23137255 -0.21568627 -0.27058824 ... -0.5372549  -0.49019608\n -0.28627451] 6\n[ 0.08235294  0.12156863 -0.21568627 ...  0.24705882  0.16862745\n  0.2627451 ] 9\n",
      "[ 0.67058824 -0.02745098 -0.34117647 ... -0.92156863 -0.65490196\n -0.15294118] 5\n[1.         0.99215686 1.         ... 0.99215686 0.99215686 0.99215686] 6\n[0.84313725 0.79607843 0.78823529 ... 0.38039216 0.37254902 0.35686275] 1\n",
      "[-0.76470588 -0.77254902 -0.74901961 ... -0.67058824 -0.62352941\n -0.49803922] 4\n[ 0.0745098   0.58431373  0.49019608 ... -0.19215686 -0.2627451\n -0.27843137] 2\n[-0.42745098 -0.41960784 -0.41176471 ... -0.46666667 -0.43529412\n -0.48235294] 7\n",
      "[0.2        0.29411765 0.21568627 ... 0.29411765 0.2627451  0.30196078] 7\n[-0.09019608 -0.06666667 -0.04313725 ... -0.83529412 -0.95294118\n -0.99215686] 1\n[-0.52156863 -0.52941176 -0.5372549  ... -0.23921569 -0.24705882\n -0.27843137] 7\n",
      "[ 0.25490196  0.27058824  0.28627451 ... -0.45882353 -0.45882353\n -0.46666667] 8\n[-0.08235294 -0.12156863 -0.12156863 ... -0.60784314 -0.6\n -0.41960784] 6\n[0.14509804 0.15294118 0.16078431 ... 0.1372549  0.1372549  0.1372549 ] 8\n",
      "[-0.51372549 -0.49803922 -0.51372549 ... -0.1372549  -0.12941176\n -0.11372549] 3\n[-0.1372549  -0.01960784  0.12941176 ...  0.0745098   0.28627451\n  0.44313725] 7\n[ 0.70980392  0.74117647  0.73333333 ... -0.1372549  -0.12941176\n -0.12156863] 8\n",
      "[-0.69411765 -0.7254902  -0.74901961 ... -0.56862745 -0.55294118\n -0.48235294] 4\n[ 0.49019608  0.55294118  0.54509804 ... -0.86666667 -0.59215686\n  0.49803922] 0\n[-0.18431373 -0.21568627 -0.22352941 ... -0.56862745 -0.52941176\n -0.54509804] 2\n",
      "[ 0.40392157  0.41176471  0.40392157 ... -0.50588235 -0.46666667\n -0.37254902] 7\n[-0.50588235 -0.48235294 -0.49803922 ...  0.46666667  0.46666667\n  0.45882353] 1\n[Train] Step: 100, loss: 2.06697, acc: 0.10000\n[ 0.03529412 -0.02745098 -0.04313725 ... -0.51372549 -0.2627451\n -0.22352941] 4\n",
      "[0.09019608 0.08235294 0.08235294 ... 0.97647059 0.96862745 1.        ] 0\n[ 0.5372549   0.50588235  0.45882353 ... -0.35686275 -0.38039216\n -0.34117647] 4\n[-0.64705882 -0.62352941 -0.59215686 ... -0.14509804 -0.05882353\n -0.02745098] 8\n",
      "[0.74901961 0.74117647 0.74901961 ... 0.82745098 0.83529412 0.88235294] 3\n[-0.8745098  -0.85882353 -0.81176471 ... -0.85882353 -0.88235294\n -0.86666667] 5\n[0.96862745 0.95294118 0.92156863 ... 0.03529412 0.00392157 0.00392157] 9\n",
      "[0.85098039 0.85882353 0.8745098  ... 0.52941176 0.12941176 0.20784314] 2\n[ 0.09019608  0.15294118  0.14509804 ... -0.34901961 -0.43529412\n -0.35686275] 8\n[-0.12941176 -0.14509804 -0.15294118 ... -0.27058824 -0.23137255\n -0.25490196] 1\n",
      "[0.5372549  0.46666667 0.4745098  ... 0.46666667 0.20784314 0.03529412] 3\n[-0.14509804  0.18431373  0.18431373 ...  0.69411765  0.65490196\n  0.61568627] 9\n[-0.65490196 -0.63921569 -0.63137255 ... -0.86666667 -0.88235294\n -0.89803922] 6\n",
      "[-0.18431373 -0.16862745 -0.16078431 ... -0.73333333 -0.67058824\n -0.6       ] 8\n[0.15294118 0.12156863 0.11372549 ... 0.34901961 0.35686275 0.34901961] 9\n[-0.58431373 -0.49803922 -0.42745098 ... -0.34117647 -0.37254902\n -0.39607843] 3\n",
      "[-0.45098039 -0.43529412 -0.3254902  ... -0.95294118 -0.90588235\n -0.74901961] 9\n[0.36470588 0.38039216 0.50588235 ... 0.52156863 0.84313725 0.92941176] 9\n[-0.16862745  0.15294118  0.12156863 ...  0.46666667  0.45098039\n  0.42745098] 1\n",
      "[ 0.23137255  0.39607843  0.33333333 ... -0.76470588 -0.75686275\n -0.79607843] 3\n[-0.34117647 -0.31764706 -0.30196078 ... -0.5372549  -0.54509804\n -0.55294118] 5\n[ 0.06666667 -0.39607843 -0.68627451 ...  0.34117647  0.34117647\n  0.34117647] 1\n",
      "[-0.33333333 -0.69411765 -0.52941176 ...  0.30980392  0.29411765\n  0.30196078] 1\n[0.51372549 0.50588235 0.50588235 ... 0.68627451 0.67058824 0.6627451 ] 6\n[ 0.16078431 -0.20784314 -0.78823529 ...  0.06666667  0.0745098\n  0.17647059] 5\n",
      "[-0.77254902 -0.81960784 -0.8745098  ...  0.00392157 -0.00392157\n -0.01960784] 1\n[0.0745098  0.12156863 0.14509804 ... 0.37254902 0.04313725 0.34901961] 2\n[-0.52941176 -0.42745098 -0.46666667 ... -0.41176471 -0.41176471\n -0.41176471] 9\n",
      "[-0.49803922 -0.54509804 -0.57647059 ...  0.04313725 -0.04313725\n -0.04313725] 7\n[ 0.05882353  0.29411765  0.06666667 ... -0.89019608 -0.89019608\n -0.88235294] 7\n[0.0745098  0.04313725 0.02745098 ... 0.37254902 0.38823529 0.38823529] 0\n",
      "[ 0.31764706  0.33333333  0.30980392 ... -0.5372549  -0.52156863\n -0.51372549] 9\n[-0.03529412 -0.04313725 -0.01960784 ... -0.06666667 -0.0745098\n -0.03529412] 7\n[-0.06666667 -0.05882353  0.00392157 ... -0.15294118 -0.15294118\n -0.14509804] 8\n",
      "[-0.08235294 -0.05098039 -0.00392157 ... -0.00392157 -0.01176471\n -0.01960784] 1\n[ 0.4745098   0.44313725  0.43529412 ... -0.44313725 -0.44313725\n -0.45882353] 0\n[ 0.27058824  0.10588235 -0.11372549 ...  0.74117647  0.52156863\n  0.12156863] 6\n",
      "[-0.74117647 -0.7254902  -0.70980392 ... -0.06666667 -0.0745098\n -0.12156863] 9\n[-0.06666667 -0.09803922 -0.06666667 ... -0.1372549  -0.62352941\n -0.17647059] 6\n[-0.17647059 -0.16862745 -0.17647059 ...  0.17647059  0.18431373\n  0.17647059] 0\n",
      "[-0.62352941 -0.55294118 -0.46666667 ...  0.5372549   0.49803922\n  0.40392157] 2\n[-0.89803922 -0.90588235 -0.91372549 ...  0.49019608  0.48235294\n  0.49019608] 5\n[-0.49019608 -0.49803922 -0.50588235 ...  0.21568627  0.18431373\n  0.18431373] 0\n",
      "[-0.92941176 -0.85098039 -0.84313725 ... -0.8745098  -0.86666667\n -0.89019608] 5\n[-0.10588235 -0.09019608 -0.16078431 ... -0.2        -0.49019608\n -0.49803922] 7\n[ 0.2         0.22352941  0.23137255 ... -0.23921569 -0.21568627\n -0.25490196] 3\n",
      "[ 0.6627451   0.31764706  0.05098039 ... -0.78039216 -0.7254902\n -0.56862745] 1\n[0.0745098  0.12941176 0.10588235 ... 0.74117647 0.74117647 0.41960784] 7\n[0.42745098 0.39607843 0.52941176 ... 0.57647059 0.45882353 0.29411765] 1\n",
      "[-0.44313725 -0.43529412 -0.43529412 ...  0.41960784  0.41176471\n  0.28627451] 5\n[ 0.04313725  0.05882353  0.04313725 ... -0.00392157 -0.41176471\n -0.55294118] 6\n[-0.9372549  -0.94509804 -0.89019608 ... -0.92156863 -0.90588235\n -0.90588235] 5\n",
      "[0.85098039 0.89803922 0.92941176 ... 0.25490196 0.22352941 0.19215686] 8\n[0.16862745 0.16078431 0.14509804 ... 0.3254902  0.34901961 0.39607843] 0\n[ 0.02745098  0.05882353  0.09019608 ... -0.17647059 -0.16078431\n -0.19215686] 3\n",
      "[0.5372549  0.48235294 0.51372549 ... 0.38823529 0.41960784 0.4745098 ] 0\n[ 0.88235294  0.86666667  0.88235294 ... -0.45098039 -0.44313725\n -0.46666667] 9\n[-0.56862745 -0.59215686 -0.58431373 ... -0.65490196 -0.67058824\n -0.55294118] 6\n",
      "[ 0.3254902   0.18431373 -0.27843137 ... -0.68627451 -0.62352941\n -0.71764706] 5\n[-0.81176471 -0.8745098  -0.81176471 ...  0.0745098   0.09019608\n  0.00392157] 7\n[-0.20784314 -0.24705882 -0.27843137 ... -0.00392157 -0.05882353\n  0.00392157] 1\n",
      "[0.18431373 0.31764706 0.35686275 ... 0.67843137 0.70196078 0.6627451 ] 3\n[-0.25490196 -0.27058824 -0.2627451  ... -0.50588235 -0.50588235\n -0.48235294] 4\n[-0.58431373 -0.50588235 -0.50588235 ... -0.67058824 -0.68627451\n -0.70196078] 1\n",
      "[ 0.37254902 -0.29411765 -0.42745098 ... -0.10588235  0.00392157\n  0.15294118] 7\n[-0.82745098 -0.81960784 -0.79607843 ...  0.7254902   0.7254902\n  0.74901961] 6\n[ 0.05882353  0.2627451  -0.01960784 ... -0.56862745 -0.64705882\n -0.70196078] 2\n",
      "[1.         0.98431373 0.98431373 ... 0.98431373 0.98431373 0.98431373] 9\n[0.19215686 0.15294118 0.14509804 ... 0.10588235 0.09803922 0.0745098 ] 5\n[-0.05098039 -0.17647059 -0.18431373 ... -0.34901961 -0.41176471\n -0.3254902 ] 4\n",
      "[-0.74117647 -0.61568627 -0.57647059 ... -0.39607843 -0.25490196\n -0.23921569] 4\n[-0.63137255 -0.63137255 -0.63137255 ...  0.74901961  0.74901961\n  0.80392157] 1\n[-0.97647059 -0.82745098 -0.75686275 ... -0.0745098  -0.0745098\n -0.05882353] 1\n",
      "[-0.38039216 -0.52941176 -0.35686275 ... -0.41176471 -0.37254902\n -0.33333333] 7\n[-0.01176471 -0.09803922 -0.0745098  ...  0.38823529  0.42745098\n  0.43529412] 5\n[-0.45098039 -0.7254902  -0.79607843 ... -0.24705882 -0.45098039\n -0.80392157] 5\n",
      "[-0.24705882 -0.38039216 -0.54509804 ... -0.14509804 -0.12156863\n -0.04313725] 1\n[-0.0745098   0.04313725  0.04313725 ... -0.61568627 -0.56862745\n -0.59215686] 6\n[-0.41176471 -0.41176471 -0.36470588 ... -0.52941176 -0.52156863\n -0.54509804] 7\n",
      "[ 0.99215686  0.99215686  1.         ... -0.57647059 -0.58431373\n -0.51372549] 2\n[-0.38823529 -0.37254902 -0.31764706 ... -0.01960784  0.10588235\n  0.1372549 ] 8\n[0.04313725 0.0745098  0.12156863 ... 0.54509804 0.50588235 0.49019608] 9\n",
      "[1. 1. 1. ... 1. 1. 1.] 3\n[-0.0745098  -0.09019608 -0.06666667 ... -0.0745098  -0.06666667\n -0.0745098 ] 1\n[ 0.4745098   0.52156863  0.56862745 ... -0.96862745 -0.95294118\n -0.96862745] 0\n",
      "[0.57647059 0.58431373 0.61568627 ... 0.3254902  0.35686275 0.50588235] 6\n[-0.63921569 -0.6        -0.4745098  ... -0.35686275 -0.36470588\n -0.38823529] 5\n[-0.12941176 -0.09019608 -0.03529412 ... -0.05098039 -0.41960784\n -0.5372549 ] 6\n",
      "[0.1372549  0.16078431 0.15294118 ... 0.58431373 0.57647059 0.55294118] 0\n[-0.45882353 -0.45098039 -0.43529412 ... -0.27843137 -0.30196078\n -0.3254902 ] 3\n[-0.37254902 -0.36470588 -0.48235294 ... -0.55294118 -0.63137255\n -0.73333333] 4\n",
      "[ 0.70980392  0.70196078  0.70980392 ... -0.41960784 -0.56862745\n -0.56862745] 1\n[ 0.92941176  0.96862745  0.97647059 ... -0.46666667 -0.4745098\n -0.49803922] 9\n[0.0745098  0.06666667 0.0745098  ... 0.4745098  0.4745098  0.45882353] 9\n",
      "[-0.80392157 -0.81960784 -0.76470588 ... -0.56078431 -0.63921569\n -0.69411765] 4\n[-0.0745098  -0.09803922 -0.09803922 ... -0.38823529 -0.42745098\n -0.43529412] 8\n[ 0.35686275  0.36470588  0.41960784 ... -0.16078431 -0.15294118\n -0.15294118] 1\n",
      "[-0.41176471 -0.36470588 -0.30980392 ...  0.60784314  0.27058824\n  0.30196078] 3\n[ 0.18431373  0.22352941  0.29411765 ... -0.22352941 -0.12941176\n -0.05882353] 4\n[1.         0.99215686 0.99215686 ... 0.12941176 0.16078431 0.16078431] 9\n",
      "[Train] Step: 200, loss: 1.63578, acc: 0.40000\n[-0.52941176 -0.50588235 -0.4745098  ... -0.30196078 -0.30980392\n -0.31764706] 2\n[0.48235294 0.45882353 0.48235294 ... 0.48235294 0.46666667 0.4745098 ] 8\n[0.94509804 0.91372549 0.91372549 ... 0.41176471 0.42745098 0.43529412] 1\n",
      "[-0.0745098  -0.06666667 -0.02745098 ... -0.02745098 -0.00392157\n  0.01960784] 7\n[-0.60784314 -0.45098039 -0.52156863 ...  0.42745098  0.42745098\n  0.34901961] 4\n[ 1.          0.96078431  0.96078431 ...  0.45882353  0.05098039\n -0.22352941] 0\n",
      "[0.30196078 0.30196078 0.30980392 ... 0.1372549  0.12156863 0.17647059] 0\n[ 0.00392157 -0.02745098 -0.04313725 ...  0.61568627  0.63137255\n  0.63137255] 0\n[ 0.63137255  0.67058824 -0.04313725 ... -0.70196078 -0.63921569\n -0.54509804] 2\n",
      "[-0.27843137 -0.25490196 -0.23921569 ...  0.15294118  0.16862745\n  0.25490196] 1\n[ 0.49019608  0.68627451  0.86666667 ... -0.09803922 -0.0745098\n -0.00392157] 3\n[0.99215686 0.92156863 0.91372549 ... 1.         0.99215686 1.        ] 9\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-fc36cf23398f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m             feed_dict={\n\u001b[0;32m     17\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                 y: batch_labels})\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             print('[Train] Step: %d, loss: %4.5f, acc: %4.5f' \n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "batch_size = 20\n",
    "train_steps = 1000\n",
    "test_steps = 100\n",
    "\n",
    "\n",
    "# train 10k: 73.4%\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(train_steps):\n",
    "        batch_data, batch_labels = train_data.next_batch(batch_size)\n",
    "        loss_val, acc_val, _ = sess.run(\n",
    "            [loss, accuracy, train_op],\n",
    "            feed_dict={\n",
    "                x: batch_data,\n",
    "                y: batch_labels})\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('[Train] Step: %d, loss: %4.5f, acc: %4.5f' \n",
    "                  % (i+1, loss_val, acc_val))\n",
    "        if (i+1) % 1000 == 0:\n",
    "            test_data = CifarData(test_filenames, False)\n",
    "            all_test_acc_val = []\n",
    "            for j in range(test_steps):\n",
    "                test_batch_data, test_batch_labels \\\n",
    "                    = test_data.next_batch(batch_size)\n",
    "                test_acc_val = sess.run(\n",
    "                    [accuracy],\n",
    "                    feed_dict = {\n",
    "                        x: test_batch_data, \n",
    "                        y: test_batch_labels\n",
    "                    })\n",
    "                all_test_acc_val.append(test_acc_val)\n",
    "            test_acc = np.mean(all_test_acc_val)\n",
    "            print('[Test ] Step: %d, acc: %4.5f'\n",
    "                  % (i+1, test_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}